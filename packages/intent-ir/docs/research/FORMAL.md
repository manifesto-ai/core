# Formal Definitions and Proofs

> **Status:** Research Document
> **Version:** 0.1.0
> **Audience:** Formal methods researchers, type theorists, verification engineers
> **Normative Authority:** This document is INFORMATIVE. For normative specifications, see [SPEC-v0.2.0](../SPEC-v0.2.0.md).
> **References:** See [BIBLIOGRAPHY.bib](./BIBLIOGRAPHY.bib)

---

## Table of Contents

1. [Introduction](#1-introduction)
2. [Type System](#2-type-system)
3. [Normalization Equivalence](#3-normalization-equivalence)
4. [Feature Checking](#4-feature-checking)
5. [Reference Resolution](#5-reference-resolution)
6. [Key Derivation](#6-key-derivation)
7. [Correctness Properties](#7-correctness-properties)

---

## 1. Introduction

This document provides formal definitions and proofs for the key properties of Intent IR. We use standard mathematical notation and type-theoretic conventions.

### 1.1 Notation

| Symbol | Meaning |
|--------|---------|
| `:` | Type annotation (e.g., `x : T` means x has type T) |
| `â†’` | Function type |
| `Ã—` | Product type |
| `+` | Sum type (disjoint union) |
| `âˆ€` | Universal quantification |
| `âˆƒ` | Existential quantification |
| `âŠ¢` | Entailment/derivability |
| `â‰¡` | Definitional equality |
| `â‰ˆ` | Semantic equivalence |
| `âŸ¦Â·âŸ§` | Semantic interpretation |
| `ğ’(Â·)` | Canonicalization function |
| `â„’` | Lexicon |
| `Î£` | Snapshot |

### 1.2 Preliminaries

We assume familiarity with:
- Basic type theory [Pierce, 2002]
- Algebraic data types
- Fixed-point semantics
- Hash functions and collision resistance

---

## 2. Type System

### 2.1 Core Types

We define Intent IR types as algebraic data types:

**Definition 2.1 (Force):**
```
Force ::= ASK | DO | VERIFY | CONFIRM | CLARIFY
```

**Definition 2.2 (EventClass):**
```
EventClass ::= OBSERVE | TRANSFORM | SOLVE | CREATE | DECIDE | CONTROL
```

**Definition 2.3 (Role):**
```
Role ::= TARGET | THEME | SOURCE | DEST | INSTRUMENT | BENEFICIARY
```

**Definition 2.4 (Modality):**
```
Modality ::= MUST | SHOULD | MAY | FORBID
```

**Definition 2.5 (TimeKind):**
```
TimeKind ::= NOW | AT | BEFORE | AFTER | WITHIN
```

**Definition 2.6 (Term):**
```
Term ::= EntityRefTerm
       | PathRefTerm
       | ArtifactRefTerm
       | ValueTerm
       | ExprTerm

EntityRefTerm ::= âŸ¨entity, entityType: String, ref: EntityRef?âŸ©
EntityRef ::= âŸ¨kind: this | that | last | id, id: String?âŸ©

PathRefTerm ::= âŸ¨path, path: StringâŸ©

ArtifactRefTerm ::= âŸ¨artifact, artifactType: ArtifactType, ref: ArtifactRef, content: String?âŸ©
ArtifactType ::= text | math | code | data | plan | mixed
ArtifactRef ::= âŸ¨kind: inline | id, id: String?âŸ©

ValueTerm ::= âŸ¨value, valueType: ValueType, shape: Map String Any, raw: Any?âŸ©
ValueType ::= string | number | boolean | date | enum | id

ExprTerm ::= âŸ¨expr, exprType: ExprType, expr: String | ObjectâŸ©
ExprType ::= latex | ast | code
```

**Definition 2.7 (Pred):**
```
Pred ::= âŸ¨lhs: ScopedPath, op: PredOp, rhs: TermâŸ©
PredOp ::= = | != | < | > | <= | >= | contains | startsWith | matches
ScopedPath ::= Prefix "." Path
Prefix ::= target | theme | source | dest | state | env | computed
```

**Definition 2.8 (IntentIR):**
```
IntentIR ::= âŸ¨
  v: "0.1",
  force: Force,
  event: Event,
  args: Map Role Term,
  cond: List Pred,
  mod: Modality?,
  time: TimeSpec?,
  verify: VerifySpec?,
  out: OutputSpec?,
  ext: Map String Any?
âŸ©

Event ::= âŸ¨lemma: String, class: EventClassâŸ©
TimeSpec ::= âŸ¨kind: TimeKind, value: Any?âŸ©
VerifySpec ::= âŸ¨mode: VerifyMode, spec: Map String Any?âŸ©
OutputSpec ::= âŸ¨type: OutputType, format: OutputFormat?, constraints: Map String Any?âŸ©
```

### 2.2 Well-Formedness

**Definition 2.9 (Well-Formed Term):**

A term `t : Term` is well-formed (written `âŠ¢ t wf`) iff:

```
âŠ¢ t : EntityRefTerm wf  âŸº  t.kind = "entity"
                          âˆ§ t.entityType â‰  ""
                          âˆ§ (t.ref.kind = "id" âŸ¹ t.ref.id â‰  undefined)

âŠ¢ t : PathRefTerm wf    âŸº  t.kind = "path" âˆ§ t.path â‰  ""

âŠ¢ t : ArtifactRefTerm wf âŸº t.kind = "artifact"
                          âˆ§ (t.ref.kind = "inline" âŸ¹ t.content â‰  undefined)
                          âˆ§ (t.ref.kind = "id" âŸ¹ t.ref.id â‰  undefined)

âŠ¢ t : ValueTerm wf      âŸº  t.kind = "value" âˆ§ t.shape â‰  {}

âŠ¢ t : ExprTerm wf       âŸº  t.kind = "expr"
                          âˆ§ (t.exprType = "ast" âŸ¹ typeof t.expr = "object")
                          âˆ§ (t.exprType âˆˆ {latex, code} âŸ¹ typeof t.expr = "string")
```

**Definition 2.10 (Well-Formed IntentIR):**

An IntentIR `ir` is well-formed (written `âŠ¢ ir wf`) iff:

```
âŠ¢ ir wf  âŸº  ir.v = "0.1"
           âˆ§ ir.force âˆˆ Force
           âˆ§ ir.event.class âˆˆ EventClass
           âˆ§ ir.event.lemma matches /^[A-Z][A-Z0-9_]*$/
           âˆ§ âˆ€(role, term) âˆˆ ir.args. role âˆˆ Role âˆ§ âŠ¢ term wf
           âˆ§ âˆ€pred âˆˆ ir.cond. âŠ¢ pred wf
```

---

## 3. Normalization Equivalence

### 3.1 Canonicalization Function

**Definition 3.1 (Canonicalization):**

Let `ğ’ : IntentIR â†’ CanonicalIR` be the canonicalization function defined as:

```
ğ’(ir) = serialize(normalize(ir))

normalize(ir) = {
  v: ir.v,
  force: ir.force,
  event: { lemma: upper(trim(ir.event.lemma)), class: ir.event.class },
  args: sortByKey(mapValues(ir.args, normalizeTerm)),
  cond: sort(map(ir.cond, normalizePred)),
  mod: ir.mod if ir.mod â‰  undefined,
  time: ir.time if ir.time â‰  undefined,
  verify: ir.verify if ir.verify â‰  undefined,
  out: ir.out if ir.out â‰  undefined,
  ext: ir.ext if ir.ext â‰  {} âˆ§ ir.ext â‰  undefined
}

normalizeTerm(t) = match t.kind with
  | "entity" â†’ removeEmptyRef(t)
  | "value" â†’ { ...t, raw: undefined }  // Semantic mode
  | _ â†’ t

normalizePred(p) = âŸ¨
  lhs: p.lhs,
  op: p.op,
  rhs: normalizeTerm(p.rhs)
âŸ©

serialize(ir) = JCS(ir)  // RFC 8785 JSON Canonicalization
```

### 3.2 Equivalence Relation

**Definition 3.2 (Semantic Equivalence):**

Two IntentIRs `irâ‚` and `irâ‚‚` are semantically equivalent (written `irâ‚ â‰ˆ irâ‚‚`) iff:

```
irâ‚ â‰ˆ irâ‚‚  âŸº  ğ’(irâ‚) = ğ’(irâ‚‚)
```

where `=` denotes byte-level string equality.

**Theorem 3.1 (Equivalence Relation):**

The relation `â‰ˆ` is an equivalence relation. That is, for all well-formed IntentIRs `irâ‚, irâ‚‚, irâ‚ƒ`:

1. **Reflexivity:** `irâ‚ â‰ˆ irâ‚`
2. **Symmetry:** `irâ‚ â‰ˆ irâ‚‚ âŸ¹ irâ‚‚ â‰ˆ irâ‚`
3. **Transitivity:** `irâ‚ â‰ˆ irâ‚‚ âˆ§ irâ‚‚ â‰ˆ irâ‚ƒ âŸ¹ irâ‚ â‰ˆ irâ‚ƒ`

**Proof:**

1. **Reflexivity:**
   - By definition, `ğ’(irâ‚) = ğ’(irâ‚)` (string equality is reflexive).
   - Therefore, `irâ‚ â‰ˆ irâ‚`. âˆ

2. **Symmetry:**
   - Assume `irâ‚ â‰ˆ irâ‚‚`, i.e., `ğ’(irâ‚) = ğ’(irâ‚‚)`.
   - String equality is symmetric, so `ğ’(irâ‚‚) = ğ’(irâ‚)`.
   - Therefore, `irâ‚‚ â‰ˆ irâ‚`. âˆ

3. **Transitivity:**
   - Assume `irâ‚ â‰ˆ irâ‚‚` and `irâ‚‚ â‰ˆ irâ‚ƒ`.
   - Then `ğ’(irâ‚) = ğ’(irâ‚‚)` and `ğ’(irâ‚‚) = ğ’(irâ‚ƒ)`.
   - By transitivity of string equality, `ğ’(irâ‚) = ğ’(irâ‚ƒ)`.
   - Therefore, `irâ‚ â‰ˆ irâ‚ƒ`. âˆ

**Theorem 3.2 (Idempotence):**

The canonicalization function is idempotent:

```
âˆ€ ir. ğ’(ğ’(ir)) = ğ’(ir)
```

**Proof:**

Let `ir' = ğ’(ir)` (as a parsed object from the serialized string).

By construction of `normalize`:
- `ir'.event.lemma` is already uppercase and trimmed
- `ir'.args` keys are already sorted
- `ir'.cond` predicates are already sorted
- Empty optional fields are already removed

Therefore, `normalize(ir') = ir'` (modulo serialization), and `ğ’(ir') = ğ’(ir)`. âˆ

**Theorem 3.3 (Order Invariance for Conditions):**

Condition order does not affect equivalence:

```
âˆ€ ir, Ï€ (permutation of ir.cond).
  ir[cond := Ï€(ir.cond)] â‰ˆ ir
```

**Proof:**

Let `ir' = ir[cond := Ï€(ir.cond)]`.

By definition of `normalize`:
```
normalize(ir).cond = sort(map(ir.cond, normalizePred))
normalize(ir').cond = sort(map(Ï€(ir.cond), normalizePred))
```

Since `sort` produces the same output for any permutation of the same set:
```
sort(map(Ï€(ir.cond), normalizePred)) = sort(map(ir.cond, normalizePred))
```

Therefore, `normalize(ir) = normalize(ir')`, and thus `ir â‰ˆ ir'`. âˆ

---

## 4. Feature Checking

### 4.1 Lexicon Structure

**Definition 4.1 (Lexicon):**

A Lexicon `â„’` is a tuple `âŸ¨E, EntâŸ©` where:
- `E : Map Lemma EventEntry` maps lemmas to event specifications
- `Ent : Map EntityType EntitySpec` maps entity types to specifications

```
EventEntry ::= âŸ¨
  eventClass: EventClass,
  thetaFrame: ThetaFrame,
  footprint: Footprint?,
  policyHints: PolicyHints?
âŸ©

ThetaFrame ::= âŸ¨
  required: List Role,
  optional: List Role,
  restrictions: Map Role SelectionalRestriction
âŸ©

SelectionalRestriction ::= âŸ¨
  termKinds: List TermKind,
  entityTypes: List EntityType?,
  valueTypes: List ValueType?
âŸ©
```

### 4.2 Typing Judgment

**Definition 4.2 (Feature Checking Judgment):**

The judgment `â„’ âŠ¢ ir âœ“` means IntentIR `ir` is valid with respect to Lexicon `â„’`.

**Inference Rules:**

```
[IR-VALID]
                â„’ âŠ¢ ir.event âœ“á´±    â„’ âŠ¢ ir.args âœ“á´¬
               â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                         â„’ âŠ¢ ir âœ“

[EVENT-VALID]
               â„’.E(ir.event.lemma) = entry
               entry.eventClass = ir.event.class
               â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                      â„’ âŠ¢ ir.event âœ“á´±

[ARGS-VALID]
               âˆ€ r âˆˆ entry.thetaFrame.required. r âˆˆ dom(ir.args)
               âˆ€ (r, t) âˆˆ ir.args. â„’ âŠ¢ t âœ“áµ€(entry.thetaFrame.restrictions(r))
               â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                      â„’ âŠ¢ ir.args âœ“á´¬

[TERM-VALID]
               t.kind âˆˆ restriction.termKinds
               (t.kind = "entity" âˆ§ restriction.entityTypes â‰  âˆ…)
                  âŸ¹ t.entityType âˆˆ restriction.entityTypes
               (t.kind = "value" âˆ§ restriction.valueTypes â‰  âˆ…)
                  âŸ¹ t.valueType âˆˆ restriction.valueTypes
               â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                         â„’ âŠ¢ t âœ“áµ€(restriction)
```

### 4.3 Soundness

**Theorem 4.1 (Decidability):**

Feature checking is decidable: there exists an algorithm that, given `â„’` and `ir`, terminates and returns either `valid` or `invalid(reason)`.

**Proof:**

The checking algorithm performs:
1. Finite lookup in `â„’.E` (by lemma)
2. Finite comparison of event class
3. Finite iteration over required roles
4. Finite iteration over args entries
5. Finite membership tests in finite sets

All operations are bounded and terminating. âˆ

**Theorem 4.2 (Completeness of Error Messages):**

If `â„’ âŠ¬ ir âœ“`, then the algorithm returns one of:
- `UNKNOWN_LEMMA`: `ir.event.lemma âˆ‰ dom(â„’.E)`
- `CLASS_MISMATCH`: `entry.eventClass â‰  ir.event.class`
- `MISSING_ROLE(r)`: `r âˆˆ entry.required âˆ§ r âˆ‰ dom(ir.args)`
- `TYPE_MISMATCH(r)`: `â„’ âŠ¬ ir.args(r) âœ“áµ€(restriction)`

**Proof:**

By case analysis on the inference rules. Each rule has a decidable premise whose failure corresponds to exactly one error type. âˆ

---

## 5. Reference Resolution

### 5.1 Discourse Model

**Definition 5.1 (Discourse State):**

A discourse state `D` is a triple `âŸ¨focus, history, entitiesâŸ©` where:
- `focus : EntityType â†’ EntityId?` maps types to currently focused entity
- `history : List (EntityType Ã— EntityId)` is the sequence of mentioned entities
- `entities : Map EntityId Entity` is the entity store

### 5.2 Resolution Function

**Definition 5.2 (Resolver):**

The resolver `R : Term Ã— Î£ Ã— D â†’ ResolvedTerm` maps symbolic references to concrete IDs.

```
R(t, Î£, D) = match t with
  | âŸ¨entity, type, ref: âŸ¨thisâŸ©âŸ© â†’ âŸ¨entity, type, ref: âŸ¨id, D.focus(type)âŸ©âŸ©
  | âŸ¨entity, type, ref: âŸ¨thatâŸ©âŸ© â†’ âŸ¨entity, type, ref: âŸ¨id, previous(D, type)âŸ©âŸ©
  | âŸ¨entity, type, ref: âŸ¨lastâŸ©âŸ© â†’ âŸ¨entity, type, ref: âŸ¨id, mostRecent(Î£, type)âŸ©âŸ©
  | âŸ¨entity, type, ref: âŸ¨id, idâŸ©âŸ© â†’ t  // Already resolved
  | âŸ¨entity, type, ref: undefinedâŸ© â†’ t  // Collection scope
  | _ â†’ t  // Non-entity terms pass through
```

**Definition 5.3 (Resolved IntentIR):**

An IntentIR is resolved (written `resolved(ir)`) iff:

```
resolved(ir) âŸº âˆ€(r, t) âˆˆ ir.args.
  t.kind = "entity" âŸ¹ (t.ref = undefined âˆ¨ t.ref.kind = "id")
```

### 5.3 Determinism

**Theorem 5.1 (Resolution Determinism):**

Given fixed `Î£` and `D`, resolution is deterministic:

```
âˆ€ t, Î£, D. R(t, Î£, D) = R(t, Î£, D)
```

**Proof:**

`R` is a pure function with no side effects. Each case in the match produces a unique output determined solely by the inputs. âˆ

**Theorem 5.2 (Resolution Completeness):**

If `âŠ¢ ir wf` and all referenced entities exist in `D`, then resolution succeeds:

```
âˆ€ ir, Î£, D. âŠ¢ ir wf âˆ§ complete(ir, D) âŸ¹ âˆƒ ir'. ir' = resolve(ir, Î£, D) âˆ§ resolved(ir')
```

where `complete(ir, D)` means all symbolic references in `ir` have corresponding entities in `D`.

---

## 6. Key Derivation

### 6.1 StrictKey

**Definition 6.1 (StrictKey):**

The strictKey derivation function `K_s : ResolvedIR Ã— Footprint Ã— Î£ Ã— Context â†’ Hash` is:

```
K_s(ir, fp, Î£, ctx) = SHA256(JCS({
  schemaHash: ctx.schemaHash,
  constitutionFP: ctx.constitutionFingerprint,
  invariantFP: ctx.invariantFingerprint,
  ir: ğ’_strict(ir),
  subsnapshot: ğ’(extract(Î£, closure(fp))),
  context: ğ’({
    env: ctx.env,
    tenant: ctx.tenant,
    permissions: sort(ctx.permissions),
    focusFingerprint: ctx.focusFingerprint,
    discourseFingerprint: ctx.discourseFingerprint
  })
}))

closure(fp) = fp.reads âˆª fp.depends âˆª fp.verify âˆª fp.policy
```

**Theorem 6.1 (StrictKey Uniqueness):**

For cryptographically secure hash function SHA256, the probability of collision is negligible:

```
Pr[K_s(irâ‚, ...) = K_s(irâ‚‚, ...) | irâ‚ â‰  irâ‚‚] â‰¤ 2â»Â¹Â²â¸
```

**Proof:**

By the collision resistance property of SHA256 [NIST, 2015]. The probability of finding distinct inputs with the same hash is bounded by the birthday paradox at approximately 2â»Â¹Â²â¸ for a 256-bit hash. âˆ

**Theorem 6.2 (StrictKey Reproducibility):**

Same inputs produce the same strictKey:

```
âˆ€ ir, fp, Î£, ctx. K_s(ir, fp, Î£, ctx) = K_s(ir, fp, Î£, ctx)
```

**Proof:**

`K_s` is composed of deterministic functions:
- JCS is deterministic (RFC 8785)
- SHA256 is deterministic
- `ğ’_strict` is deterministic (Theorem 3.2)
- `extract` and `closure` are pure functions âˆ

### 6.2 SimKey

**Definition 6.2 (SimKey):**

The simKey derivation function `K_sim : IntentIR â†’ SimHash` is:

```
K_sim(ir) = SimHash(tokenize(ğ’_semantic(ir)))

tokenize(ir) = flatten([
  ir.force,
  ir.event.lemma,
  ir.event.class,
  ...flatMap(ir.args, (r, t) â†’ [r, tokenizeTerm(t)]),
  ...flatMap(ir.cond, tokenizePred)
])

tokenizeTerm(t) = match t.kind with
  | "entity" â†’ [t.entityType]
  | "value" â†’ [t.valueType, ...keys(t.shape)]
  | "expr" â†’ [t.exprType]
  | "path" â†’ [normalize(t.path)]
  | "artifact" â†’ [t.artifactType]
```

**Definition 6.3 (SimHash):**

SimHash [Charikar, 2002] produces a locality-sensitive hash:

```
SimHash(tokens) =
  let V = [0] Ã— 64
  for token in tokens:
    h = hash64(token)
    for i in 0..63:
      if bit(h, i) = 1 then V[i] += 1 else V[i] -= 1
  return bitsToInt([sign(v) for v in V])
```

**Theorem 6.3 (SimKey Collision Probability):**

For semantically similar IRs (Jaccard similarity J), the probability of bit agreement is:

```
Pr[bit_i(K_sim(irâ‚)) = bit_i(K_sim(irâ‚‚))] = (1 + J) / 2
```

where Jaccard similarity `J = |Tâ‚ âˆ© Tâ‚‚| / |Tâ‚ âˆª Tâ‚‚|` for token sets Tâ‚, Tâ‚‚.

**Proof:**

By the theoretical analysis of SimHash [Charikar, 2002], each bit is an independent estimate of the sign of a random hyperplane projection. The probability of agreement corresponds to the angle between token set vectors, which relates to Jaccard similarity for binary vectors. âˆ

---

## 7. Correctness Properties

### 7.1 System Invariants

**Invariant 7.1 (Canonical Preservation):**

Canonicalization preserves semantic content:

```
âˆ€ ir. âŸ¦irâŸ§ = âŸ¦ğ’(ir)âŸ§
```

where `âŸ¦Â·âŸ§` is the semantic interpretation function.

**Invariant 7.2 (Feature Checking Stability):**

Feature checking is invariant under canonicalization:

```
âˆ€ ir, â„’. â„’ âŠ¢ ir âœ“ âŸº â„’ âŠ¢ ğ’(ir) âœ“
```

**Invariant 7.3 (Key Determinism):**

Key derivation is deterministic:

```
âˆ€ irâ‚, irâ‚‚, ctx. irâ‚ â‰ˆ irâ‚‚ âŸ¹ K_s(irâ‚, ctx) = K_s(irâ‚‚, ctx)
```

### 7.2 Safety Properties

**Safety 7.1 (No False Equivalence):**

Canonicalization does not identify semantically distinct IRs:

```
âˆ€ irâ‚, irâ‚‚. ğ’(irâ‚) = ğ’(irâ‚‚) âŸ¹ âŸ¦irâ‚âŸ§ = âŸ¦irâ‚‚âŸ§
```

**Safety 7.2 (Validation Soundness):**

If an IR passes validation, it is well-formed:

```
âˆ€ ir, â„’. â„’ âŠ¢ ir âœ“ âŸ¹ âŠ¢ ir wf
```

### 7.3 Liveness Properties

**Liveness 7.1 (Validation Termination):**

Feature checking always terminates:

```
âˆ€ ir, â„’. âˆƒ result. check(ir, â„’) = result
```

**Liveness 7.2 (Resolution Termination):**

Reference resolution always terminates:

```
âˆ€ ir, Î£, D. âˆƒ ir'. resolve(ir, Î£, D) = ir'
```

---

## Appendix A: Proof Sketches

### A.1 Proof of Theorem 3.2 (Idempotence)

**Full proof:**

Let `ir` be any well-formed IntentIR. Define `irâ‚ = normalize(ir)` and `irâ‚‚ = normalize(irâ‚)`.

We show `irâ‚ = irâ‚‚` by structural induction:

**Base case (atoms):**
- `irâ‚.v = "0.1" = irâ‚‚.v`
- `irâ‚.force âˆˆ Force` is unchanged
- `irâ‚.event.lemma = upper(trim(lemma))` is already normalized
- `irâ‚.event.class âˆˆ EventClass` is unchanged

**Inductive case (args):**
- `irâ‚.args` has keys sorted
- `sortByKey(irâ‚.args) = irâ‚.args` (sorting an already-sorted map is identity)

**Inductive case (cond):**
- `irâ‚.cond` is already sorted
- `sort(irâ‚.cond) = irâ‚.cond` (sorting an already-sorted list is identity)

**Optional fields:**
- Empty fields are already removed in `irâ‚`
- Removing already-removed fields has no effect

Therefore, `normalize(irâ‚) = irâ‚`, and `ğ’(ğ’(ir)) = serialize(irâ‚) = ğ’(ir)`. âˆ

---

## References

See [BIBLIOGRAPHY.bib](./BIBLIOGRAPHY.bib) for full citations.

Key works:
- [Pierce, 2002] Types and Programming Languages
- [Charikar, 2002] Similarity Estimation Techniques from Rounding Algorithms
- [NIST, 2015] SHA-3 Standard
- [RFC 8785] JSON Canonicalization Scheme (JCS)

---

*End of Formal Definitions Document*
